{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c69fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3b7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable variables\n",
    "NUM_EPOCHS = 50\n",
    "NOISE_DIMENSION = 50\n",
    "BATCH_SIZE = 128\n",
    "TRAIN_ON_GPU = False\n",
    "UNIQUE_RUN_ID = str(uuid.uuid4())\n",
    "PRINT_STATS_AFTER_BATCH = 50\n",
    "OPTIMIZER_LR = 2e-4\n",
    "OPTIMIZER_BETAS = (0.5, 0.999)\n",
    "GENERATOR_OUTPUT_IMAGE_SHAPE = 28 * 28 * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99940bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed Ups\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)\n",
    "torch.bachends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195dc2f",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "145a6c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla GAN Generator\n",
    "    \"\"\"\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # First upsampling\n",
    "            nn.Linear(NOISE_DIMENSION, 128, bias=False),\n",
    "            nn.BatchNorm1d(128, momentum=0.8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Second upsampling\n",
    "            nn.Linear(128, 256, bias=False),\n",
    "            nn.BatchNorm1d(256, momentum=0.8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Third upsampling\n",
    "            nn.Linear(256, 512, bias=False),\n",
    "            nn.BatchNorm1d(512, momentum=0.8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Final upsampling\n",
    "            nn.Linear(512, GENERATOR_OUTPUT_IMAGE_SHAPE, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e3f742",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf95f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla GAN Discriminator\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(GENERATOR_OUTPUT_IMAGE_SHAPE, 1024),\n",
    "            nn.LeakyReLU(0.25),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.25),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.25),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b63463",
   "metadata": {},
   "source": [
    "## Housekeeping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9260a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\" Retrieve device based on settings and availability. \"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() and TRAIN_ON_GPU else \"cpu\")\n",
    "\n",
    "def make_directory_for_run():\n",
    "    \"\"\" Make a directory for this training run \"\"\"\n",
    "    print(f\"Preparing training run {UNIQUE_RUN_ID}\")\n",
    "    if not os.path.exists(\"./runs\"):\n",
    "        os.mkdir('./runs')\n",
    "    os.mkdir(f\"./runs/{UNIQUE_RUN_ID}\")\n",
    "    \n",
    "def generate_image(generator, epoch=0, batch=0, device=get_device()):\n",
    "    \"\"\" Genereate subplots with generated examples. \"\"\"\n",
    "    images = []\n",
    "    noise = generate_noise(BATCH_SIZE, device=device)\n",
    "    generator.eval()\n",
    "    images = generator(noise)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(16):\n",
    "        # Get iamge\n",
    "        image = images[i]\n",
    "        # Convert image back onto CPU and reshape\n",
    "        image = image.cpu().detach().numpy()\n",
    "        image = np.reshape(image, (28, 28))\n",
    "        # Plot\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    if not os.path.exists(f\"./runs/{UNIQUE_RUN_ID}/images\"):\n",
    "        os.mkdir(f\"./runs/{UNIQUE_RUN_ID}/images\")\n",
    "    plt.savefig(f\"./runs/{UNIQUE_RUN_ID}/images/epoch{epoch}_batch{batch}.jpg\")\n",
    "    \n",
    "def save_models(generator, discriminator, epoch):\n",
    "    \"\"\" Save models at specific point in time. \"\"\"\n",
    "    torch.save(generator.state_dict(), f\"./runs/{UNIQUE_RUN_ID}/generator_{epoch}.pth\")\n",
    "    torch.save(discriminator.state_dict(), f\"./runs/{UNIQUE_RUN_ID}/discriminator_{epoch}.pth\")\n",
    "    \n",
    "def print_training_progress(batch, generator_loss, discriminator_loss):\n",
    "    \"\"\" Print training progress. \"\"\"\n",
    "    print(f\"Losses after mini-batch {batch:5d}: generator {generator_loss:e}, discriminator {discriminator_loss:e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c28f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    \"\"\" Prepare dataset through DataLoader \"\"\"\n",
    "    # Prepare MNIST dataset\n",
    "    dataset = MNIST(os.getcwd(), download=True, train=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)) # range changes to [-1, 1] to match tanh in Generator\n",
    "    ]))\n",
    "    # Batch and shuffle data with DataLoader\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    # Return dataset through DataLoader\n",
    "    return trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2166177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models(device = get_device()):\n",
    "    \"\"\" Initialize Generator and Discriminator models \"\"\"\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "    # Move models to specific device\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "    # Return models\n",
    "    return generator, discriminator\n",
    "\n",
    "def initialize_loss():\n",
    "    \"\"\" Initialize loss function. \"\"\"\n",
    "    return nn.BCELoss()\n",
    "\n",
    "def initialize_optimizers(generator, discriminator):\n",
    "    \"\"\" Initialize optimizers for Generator and Discriminator \"\"\"\n",
    "    generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=OPTIMIZER_LR, betas=OPTIMIZER_BETAS)\n",
    "    discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=OPTIMIZER_LR, betas=OPTIMIZER_BETAS)\n",
    "    return generator_optimizer, discriminator_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced8b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(number_of_images = 1, noise_dimension = NOISE_DIMENSION, device=None):\n",
    "    \"\"\" Generate noise for number_of_images images, with a specific noise_dimension \"\"\"\n",
    "    return torch.randn(number_of_images, noise_dimension, device=device)\n",
    "\n",
    "def efficient_zero_grad(model):\n",
    "    \"\"\"\n",
    "    Apply zero_grad more efficiently\n",
    "    Source: https://betterprogramming.pub/how-to-make-your-pytorch-code-run-faster-93079f3c1f7b\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.grad = None\n",
    "        \n",
    "def forward_and_backward(model, data, loss_function, targets):\n",
    "    \"\"\"\n",
    "    Perform forward and backward pass in a generic way. Returns loss value.\n",
    "    \"\"\"\n",
    "    outputs = model(data)\n",
    "    error = loss_function(outputs, targets)\n",
    "    error.backward()\n",
    "    return error.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00bf59d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c634a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_train_step(generator, discriminator, real_data, \\\n",
    "    loss_function, generator_optimizer, discriminator_optimizer, device=get_device()):\n",
    "    \"\"\" Perform a single training step. \"\"\"\n",
    "    \n",
    "    # 1. PREPARATION\n",
    "    # Set real and fake labels.\n",
    "    real_label, fake_label = 1.0, 0.0\n",
    "    # Get images on CPU or PGU as configured and available\n",
    "    # Also set 'actual batch size', which can eb smaller than BATCH_SIZE in some cases.\n",
    "    # This is because the last batch of an epoch may have less examples than the others.\n",
    "    real_images = real_data[0].to(device) # retrieve the image of (image, label) from the original MNIST dataset\n",
    "    actual_batch_size = real_images.size(0)\n",
    "    label = torch.full((actual_batch_size, 1), real_label, device=device)\n",
    "    \n",
    "    # 3. TRAINING THE DISCRIMINATOR\n",
    "    # Zero the gradients for discriminator\n",
    "    efficient_zero_grad(discriminator)\n",
    "    # Forward + backward on real images, reshaped\n",
    "    real_images = real_images.view(real_images.size(0), -1) # (batch_size, 1 x 24 x 24)\n",
    "    error_real_images = forward_and_backward(discriminator, real_images, \\\n",
    "        loss_function, label)\n",
    "    # Forward + backward on generated images\n",
    "    noise = generate_noise(actual_batch_size, device=device)\n",
    "    generated_images = generator(noise)\n",
    "    label.fill_(fake_label)\n",
    "    error_generated_images = forward_and_backward(discriminator, \\\n",
    "        generated_images.detach(), loss_function, label)\n",
    "    # Optim for discriminator\n",
    "    discriminator_optimizer.step()\n",
    "    \n",
    "    # 3. TRAINING THE GENERATOR\n",
    "    # Forward + backward + optim for generator, including zero grad\n",
    "    efficient_zero_grad(generator)\n",
    "    label.fill_(real_label)\n",
    "    error_generator = forward_and_backward(discriminator, generated_images, loss_function, label)\n",
    "    generator_optimizer.step()\n",
    "    \n",
    "    # 4. COMPUTING RESULTS\n",
    "    # Compute loss values in floats for discriminator, which is joint loss.\n",
    "    error_discriminator = error_real_images + error_generated_images\n",
    "    # Return generator and discriminator loss so that it can be printed.\n",
    "    return error_generator, error_discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "188b8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_epoch(dataloader, generator, discriminator, loss_function, \\\n",
    "    generator_optimizer, discriminator_optimizer, epoch):\n",
    "    \"\"\" Perform a single epoch. \"\"\"\n",
    "    for batch_no, real_data in enumerate(dataloader, 0):\n",
    "        # Perform training step\n",
    "        generator_loss_val, discriminator_loss_val = perform_train_step(generator, \\\n",
    "            discriminator, real_data, loss_function, \\\n",
    "            generator_optimizer, discriminator_optimizer)\n",
    "        # Print statistics and generate iamge after every n-th batch\n",
    "        if batch_no % PRINT_STATS_AFTER_BATCH == 0:\n",
    "            print_training_progress(batch_no, generator_loss_val, discriminator_loss_val)\n",
    "            generate_image(generator, epoch, batch_no)\n",
    "        # Save models on epoch completion\n",
    "        save_models(generator, discriminator, epoch)\n",
    "        # Clear memory after every epoch\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a7d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training run f8b9562c-0cfc-42dd-86f4-fc1bcbcda720\n",
      "Starting epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 6.821358e-01, discriminator 1.371052e+00\n",
      "Losses after mini-batch    50: generator 9.486220e-01, discriminator 1.265845e+00\n",
      "Losses after mini-batch   100: generator 9.288982e-01, discriminator 1.391765e+00\n",
      "Losses after mini-batch   150: generator 9.200873e-01, discriminator 1.214300e+00\n",
      "Losses after mini-batch   200: generator 1.325961e+00, discriminator 9.432145e-01\n",
      "Losses after mini-batch   250: generator 8.926033e-01, discriminator 7.523752e-01\n",
      "Losses after mini-batch   300: generator 1.207826e+00, discriminator 7.872662e-01\n",
      "Losses after mini-batch   350: generator 1.794275e+00, discriminator 5.709856e-01\n",
      "Losses after mini-batch   400: generator 2.630622e+00, discriminator 1.079310e+00\n",
      "Losses after mini-batch   450: generator 1.310829e+00, discriminator 6.749234e-01\n",
      "Starting epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 3.286405e+00, discriminator 7.502441e-01\n",
      "Losses after mini-batch    50: generator 2.526597e+00, discriminator 6.209961e-01\n",
      "Losses after mini-batch   100: generator 2.311579e+00, discriminator 9.383871e-01\n",
      "Losses after mini-batch   150: generator 2.358335e+00, discriminator 5.270703e-01\n",
      "Losses after mini-batch   200: generator 2.459430e+00, discriminator 6.058400e-01\n",
      "Losses after mini-batch   250: generator 2.022813e+00, discriminator 5.303159e-01\n",
      "Losses after mini-batch   300: generator 1.952054e+00, discriminator 5.427356e-01\n",
      "Losses after mini-batch   350: generator 2.460001e+00, discriminator 5.836852e-01\n",
      "Losses after mini-batch   400: generator 1.933246e+00, discriminator 5.173903e-01\n",
      "Losses after mini-batch   450: generator 1.244366e+00, discriminator 7.715344e-01\n",
      "Starting epoch 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 1.844283e+00, discriminator 6.430355e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5268/306638063.py:18: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch    50: generator 2.950277e+00, discriminator 4.986420e-01\n",
      "Losses after mini-batch   100: generator 1.866525e+00, discriminator 1.042526e+00\n",
      "Losses after mini-batch   150: generator 1.802803e+00, discriminator 5.897691e-01\n",
      "Losses after mini-batch   200: generator 2.252990e+00, discriminator 6.471228e-01\n",
      "Losses after mini-batch   250: generator 2.357257e+00, discriminator 7.078981e-01\n",
      "Losses after mini-batch   300: generator 1.921964e+00, discriminator 6.540326e-01\n",
      "Losses after mini-batch   350: generator 2.455935e+00, discriminator 5.927333e-01\n",
      "Losses after mini-batch   400: generator 2.647455e+00, discriminator 5.649123e-01\n",
      "Losses after mini-batch   450: generator 2.049061e+00, discriminator 4.340605e-01\n",
      "Starting epoch 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 1.776047e+00, discriminator 7.464757e-01\n",
      "Losses after mini-batch    50: generator 8.638223e-01, discriminator 1.294404e+00\n",
      "Losses after mini-batch   100: generator 5.532578e-01, discriminator 1.399839e+00\n",
      "Losses after mini-batch   150: generator 2.133494e+00, discriminator 6.503580e-01\n",
      "Losses after mini-batch   200: generator 2.199848e+00, discriminator 7.439395e-01\n",
      "Losses after mini-batch   250: generator 1.457270e+00, discriminator 7.415901e-01\n",
      "Losses after mini-batch   300: generator 1.546610e+00, discriminator 6.207586e-01\n",
      "Losses after mini-batch   350: generator 2.911987e+00, discriminator 7.024477e-01\n",
      "Losses after mini-batch   400: generator 4.125157e+00, discriminator 9.426774e-01\n",
      "Losses after mini-batch   450: generator 1.488790e+00, discriminator 7.143639e-01\n",
      "Starting epoch 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 6.714826e-01, discriminator 8.527733e-01\n",
      "Losses after mini-batch    50: generator 2.120138e+00, discriminator 5.561877e-01\n",
      "Losses after mini-batch   100: generator 2.181667e+00, discriminator 5.622258e-01\n",
      "Losses after mini-batch   150: generator 9.359910e-01, discriminator 7.202892e-01\n",
      "Losses after mini-batch   200: generator 1.850514e+00, discriminator 6.086128e-01\n",
      "Losses after mini-batch   250: generator 2.190278e+00, discriminator 6.233092e-01\n",
      "Losses after mini-batch   300: generator 1.984682e+00, discriminator 5.689805e-01\n",
      "Losses after mini-batch   350: generator 1.712351e+00, discriminator 6.819035e-01\n",
      "Losses after mini-batch   400: generator 1.516251e+00, discriminator 5.978690e-01\n",
      "Losses after mini-batch   450: generator 3.147737e+00, discriminator 1.065923e+00\n",
      "Starting epoch 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 2.033937e+00, discriminator 8.341357e-01\n",
      "Losses after mini-batch    50: generator 2.613985e+00, discriminator 8.813044e-01\n",
      "Losses after mini-batch   100: generator 1.902510e+00, discriminator 6.652126e-01\n",
      "Losses after mini-batch   150: generator 3.131765e+00, discriminator 8.461483e-01\n",
      "Losses after mini-batch   200: generator 1.541710e+00, discriminator 7.788189e-01\n",
      "Losses after mini-batch   250: generator 1.723683e+00, discriminator 7.408310e-01\n",
      "Losses after mini-batch   300: generator 1.850818e+00, discriminator 7.455605e-01\n",
      "Losses after mini-batch   350: generator 2.017582e+00, discriminator 6.853232e-01\n",
      "Losses after mini-batch   400: generator 2.370290e+00, discriminator 7.878802e-01\n",
      "Losses after mini-batch   450: generator 5.348853e-01, discriminator 1.458541e+00\n",
      "Starting epoch 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 1.571191e+00, discriminator 7.706105e-01\n",
      "Losses after mini-batch    50: generator 7.680866e-01, discriminator 9.325773e-01\n",
      "Losses after mini-batch   100: generator 1.607902e+00, discriminator 8.353691e-01\n",
      "Losses after mini-batch   150: generator 1.773142e+00, discriminator 7.642600e-01\n",
      "Losses after mini-batch   200: generator 1.783865e+00, discriminator 6.878004e-01\n",
      "Losses after mini-batch   250: generator 7.145129e-01, discriminator 1.052205e+00\n",
      "Losses after mini-batch   300: generator 2.506669e+00, discriminator 9.438508e-01\n",
      "Losses after mini-batch   350: generator 1.362371e+00, discriminator 7.660693e-01\n",
      "Losses after mini-batch   400: generator 2.252081e+00, discriminator 7.970077e-01\n",
      "Losses after mini-batch   450: generator 1.243782e+00, discriminator 8.663449e-01\n",
      "Starting epoch 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 8.245392e-01, discriminator 9.423319e-01\n",
      "Losses after mini-batch    50: generator 1.675701e+00, discriminator 7.774864e-01\n",
      "Losses after mini-batch   100: generator 2.532477e+00, discriminator 9.672236e-01\n",
      "Losses after mini-batch   150: generator 1.963042e+00, discriminator 8.228761e-01\n",
      "Losses after mini-batch   200: generator 1.489735e+00, discriminator 1.090393e+00\n",
      "Losses after mini-batch   250: generator 1.384515e+00, discriminator 8.818959e-01\n",
      "Losses after mini-batch   300: generator 1.464323e+00, discriminator 9.132618e-01\n",
      "Losses after mini-batch   350: generator 1.581639e+00, discriminator 8.709914e-01\n",
      "Losses after mini-batch   400: generator 1.121489e+00, discriminator 1.030180e+00\n",
      "Losses after mini-batch   450: generator 1.726229e+00, discriminator 8.733801e-01\n",
      "Starting epoch 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 1.180437e+00, discriminator 9.028890e-01\n",
      "Losses after mini-batch    50: generator 1.170083e+00, discriminator 8.742793e-01\n",
      "Losses after mini-batch   100: generator 2.136473e+00, discriminator 1.066518e+00\n",
      "Losses after mini-batch   150: generator 7.499750e-01, discriminator 9.631000e-01\n",
      "Losses after mini-batch   200: generator 1.810656e+00, discriminator 1.011894e+00\n",
      "Losses after mini-batch   250: generator 1.299252e+00, discriminator 9.459539e-01\n",
      "Losses after mini-batch   300: generator 2.095550e+00, discriminator 1.005014e+00\n",
      "Losses after mini-batch   350: generator 2.435631e+00, discriminator 1.157133e+00\n",
      "Losses after mini-batch   400: generator 1.803940e+00, discriminator 8.878756e-01\n",
      "Losses after mini-batch   450: generator 1.273365e+00, discriminator 9.479349e-01\n",
      "Starting epoch 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsooh/ssd/t5/envs/conda_envs/vanilla-gan/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses after mini-batch     0: generator 1.898897e+00, discriminator 1.080953e+00\n",
      "Losses after mini-batch    50: generator 1.068114e+00, discriminator 9.329784e-01\n",
      "Losses after mini-batch   100: generator 1.978964e+00, discriminator 8.214071e-01\n",
      "Losses after mini-batch   150: generator 1.287008e+00, discriminator 8.903011e-01\n",
      "Losses after mini-batch   200: generator 2.062446e+00, discriminator 9.928671e-01\n",
      "Losses after mini-batch   250: generator 1.391501e+00, discriminator 9.111294e-01\n",
      "Losses after mini-batch   300: generator 1.718695e+00, discriminator 9.032275e-01\n"
     ]
    }
   ],
   "source": [
    "def train_gan():\n",
    "    \"\"\" Train the GAN \"\"\"\n",
    "    # Make directory for unique run\n",
    "    make_directory_for_run()\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(42)\n",
    "    # Get prepared dataset\n",
    "    dataloader = prepare_dataset()\n",
    "    # Initialize models\n",
    "    generator, discriminator = initialize_models()\n",
    "    # Intialize loss and optimizers\n",
    "    loss_function = initialize_loss()\n",
    "    generator_optimizer, discriminator_optimizer = initialize_optimizers(generator, discriminator)\n",
    "    # Train the model\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Starting epoch {epoch}...\")\n",
    "        perform_epoch(dataloader, generator, discriminator, loss_function, \\\n",
    "            generator_optimizer, discriminator_optimizer, epoch)\n",
    "    # Finished :-)\n",
    "    print(f\"Finished unique run {UNIQUE_RUN_ID}\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bd0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vanilla-gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
